{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034704a-da57-40e1-8862-1a76a9857ef5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3990267/1792013784.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCustomImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotations_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Loading DATA\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_files, img_dir, transform=None, target_transform=None):\n",
    "        self.image_labels = pd.read_csv(annotations_files)\n",
    "        self.img_dir = img_dir\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_lables)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = path\n",
    "        image = read_image(img_path)\n",
    "        label = (target)\n",
    "        return image, label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a0d1e3-a91b-4298-ab8f-5700a10e64fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "Prediction before training: f(5) = 3.118\n",
      "epoch 1: w = 0.865, loss = 14.659\n",
      "epoch 11: w = 1.744, loss = 0.390\n",
      "epoch 21: w = 1.888, loss = 0.020\n",
      "epoch 31: w = 1.913, loss = 0.010\n",
      "epoch 41: w = 1.919, loss = 0.009\n",
      "epoch 51: w = 1.922, loss = 0.009\n",
      "epoch 61: w = 1.925, loss = 0.008\n",
      "epoch 71: w = 1.927, loss = 0.008\n",
      "epoch 81: w = 1.929, loss = 0.007\n",
      "epoch 91: w = 1.931, loss = 0.007\n",
      "Prediction before training: f(5) = 9.862\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# f = w * x \n",
    "\n",
    "X = torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor([5], dtype = torch.float32)\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "    \n",
    "model = LinearRegression(input_size, output_size)\n",
    "        \n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # print(y_pred)\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    l.backward()\n",
    "    \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "        \n",
    "#     #zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        [w, b] = model.parameters()\n",
    "        print(f'epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.3f}')\n",
    "        \n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "878546e9-4632-46c8-aeb6-abcceb4345e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "data = []\n",
    "\n",
    "y = np.load('spec_data/answer.npy')\n",
    "\n",
    "for i in range(len(y)//1000):\n",
    "    data.append(np.load(f'spec_data/{i}.npy'))\n",
    "    \n",
    "data = np.array(data)\n",
    "# class BlockDataset(Dataset):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         xy = np.loadnp.load('spec_data/0.npy')\n",
    "#         self.x = torch.from_numpy(xy[:, 1:])\n",
    "#         self.y = torch.from_numpy(xy[:, [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ef0b6e4-b121-4222-bc3e-b4295422a0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 314, 1000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0bc661b-ec9d-47d6-8636-2130bf4be9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14490160,), (46159,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8642308-9803-4b2b-bc9c-a5f33949fd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314, 46159)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data) # input_size\n",
    "sequence_length = 1000\n",
    "hidden_size = 128\n",
    "num_layers = 3\n",
    "\n",
    "len(y) # output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99da57d7-ae14-4a02-ac10-2746b7e4015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_classes = 10\n",
    "num_epochs = 20\n",
    "batch_size = 100\n",
    "learning_rate = 1e-5\n",
    "\n",
    "input_size = 314\n",
    "sequence_length = 1000\n",
    "hidden_size = 128\n",
    "num_layers = 3\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc - nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x ):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "n_total_steps = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # training\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72613892-60e8-4314-9d89-66d1c57195fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa80c7-2472-4215-83e5-49028c63e28b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
